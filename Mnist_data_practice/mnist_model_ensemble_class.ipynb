{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,sess,name):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self._build_net()\n",
    "    def _build_net(self):#변수 설정 및 network 구성\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.learning_rate=0.001\n",
    "            \n",
    "            self.X=tf.placeholder(tf.float32,shape=[None,784])\n",
    "            self.X_img = tf.reshape(self.X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            #cnn network\n",
    "            self.L1=tf.layers.conv2d(inputs=self.X_img,filters=32,kernel_size=[3,3],padding=\"SAME\",activation=tf.nn.relu)\n",
    "            self.L1=tf.layers.max_pooling2d(inputs=self.L1,pool_size=[2,2],padding=\"SAME\",strides=2)\n",
    "            self.L1_drop=tf.layers.dropout(inputs=self.L1,rate=0.7,training=self.training)\n",
    "            \n",
    "            self.L2=tf.layers.conv2d(inputs=self.L1_drop,filters=64,kernel_size=[3,3],padding=\"SAME\",activation=tf.nn.relu)\n",
    "            self.L2=tf.layers.max_pooling2d(inputs=self.L2,pool_size=[2,2],padding=\"SAME\",strides=2)\n",
    "            self.L2_drop=tf.layers.dropout(inputs=self.L2,rate=0.7,training=self.training)\n",
    "            \n",
    "            self.L3=tf.layers.conv2d(inputs=self.L2_drop,filters=128,kernel_size=[3,3],padding=\"SAME\",activation=tf.nn.relu)\n",
    "            self.L3=tf.layers.max_pooling2d(inputs=self.L3,pool_size=[2,2],padding=\"SAME\",strides=2)\n",
    "            self.L3_drop=tf.layers.dropout(inputs=self.L3,rate=0.7,training=self.training)\n",
    "            \n",
    "            self.flat=tf.reshape(self.L3_drop,[-1,4*4*128])\n",
    "            #fully connected network\n",
    "            self.FL1=tf.layers.dense(inputs=self.flat,units=625,activation=tf.nn.relu)\n",
    "            self.FL1_drop=tf.layers.dropout(self.FL1,0.7,training=self.training)\n",
    "            \n",
    "            self.logits=tf.layers.dense(inputs=self.FL1_drop,units=10)\n",
    "            \n",
    "            #cost & optimizer\n",
    "            self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.Y))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            #accuracy & prediction\n",
    "            self.correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "    def predicted(self,x_test,training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X:x_test,self.training:training})\n",
    "    def get_accuracy(self,x_test,y_test,training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X:x_test,self.Y:y_test,self.training:training})\n",
    "    def train(self,x_data,y_data,training=True):\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict={self.X:x_data,self.Y:y_data,self.training:training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robotmedia9\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = [0.97646909 0.89665843 0.9136703  0.91228561 0.9686816  0.899685\n",
      " 0.8631625  0.91038239 0.94287076 0.88138836]\n",
      "Epoch: 0002 cost = [0.34195169 0.33731705 0.33734675 0.33603003 0.34763766 0.33072022\n",
      " 0.33743168 0.33806542 0.34829367 0.33044027]\n",
      "Epoch: 0003 cost = [0.26370975 0.2676558  0.26828072 0.26822135 0.2691241  0.26084358\n",
      " 0.26280524 0.26650742 0.26981815 0.26701984]\n",
      "Epoch: 0004 cost = [0.23305772 0.23314818 0.23620417 0.24086489 0.23605815 0.23364954\n",
      " 0.23451815 0.23039156 0.23831221 0.23369453]\n",
      "Epoch: 0005 cost = [0.20835859 0.21424956 0.21807894 0.21436056 0.21464681 0.20806126\n",
      " 0.21481723 0.21076636 0.21667431 0.21413873]\n",
      "Epoch: 0006 cost = [0.19899496 0.20206501 0.20201499 0.20320623 0.20763668 0.199385\n",
      " 0.20112415 0.20173814 0.20567189 0.20432921]\n",
      "Epoch: 0007 cost = [0.18801426 0.19058048 0.19277994 0.19210074 0.1948453  0.18661228\n",
      " 0.19188684 0.19111497 0.18781581 0.19032901]\n",
      "Epoch: 0008 cost = [0.17924817 0.18785565 0.18894019 0.1844099  0.18455735 0.17900206\n",
      " 0.18479707 0.1850917  0.18433625 0.18518801]\n",
      "Epoch: 0009 cost = [0.17611987 0.17637559 0.17951351 0.17276058 0.17923353 0.17822797\n",
      " 0.1836044  0.17824769 0.17836016 0.17805674]\n",
      "Epoch: 0010 cost = [0.17287309 0.17603719 0.17218313 0.17205282 0.17608417 0.17282409\n",
      " 0.17721372 0.17174361 0.17503771 0.16993058]\n",
      "Epoch: 0011 cost = [0.1680353  0.17393248 0.16929371 0.17286632 0.17429524 0.16856432\n",
      " 0.17085345 0.1684078  0.17135785 0.17094297]\n",
      "Epoch: 0012 cost = [0.16576725 0.16377598 0.1680242  0.16986663 0.16892804 0.16642869\n",
      " 0.17159703 0.16918553 0.16373837 0.16925214]\n",
      "Epoch: 0013 cost = [0.16063544 0.16460874 0.16819265 0.16277985 0.16788729 0.16136629\n",
      " 0.16654872 0.16109155 0.16357212 0.16437482]\n",
      "Epoch: 0014 cost = [0.16029637 0.16104711 0.16257292 0.16267913 0.16373469 0.16103678\n",
      " 0.1662653  0.16089289 0.1643451  0.16313287]\n",
      "Epoch: 0015 cost = [0.16176836 0.15462822 0.16258374 0.16367513 0.15981041 0.15652604\n",
      " 0.16539833 0.16146882 0.16183309 0.16284218]\n",
      "Learning Finished!\n",
      "learning time :  814.8812520503998\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "#load mnist data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess=tf.Session()\n",
    "models=[]\n",
    "num_models=10\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess,\"model\"+str(m)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "start_time=time.time()\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys =mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:','%04d'%(epoch + 1),'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "print('learning time : ',time.time()-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy: 0.9879\n",
      "1 Accuracy: 0.988\n",
      "2 Accuracy: 0.9881\n",
      "3 Accuracy: 0.9884\n",
      "4 Accuracy: 0.989\n",
      "5 Accuracy: 0.9876\n",
      "6 Accuracy: 0.9882\n",
      "7 Accuracy: 0.9889\n",
      "8 Accuracy: 0.988\n",
      "9 Accuracy: 0.9874\n",
      "Ensemble accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros([test_size, 10])\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predicted(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
