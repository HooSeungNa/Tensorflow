{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robotmedia9\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from read_xml import*\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self,sess,name,size):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self.size=size # min (image_w,image_h) image scaling\n",
    "        with tf.variable_scope(self.name):    \n",
    "            self.X = tf.placeholder(tf.float32, [None, self.size,self.size,3]) # image data \n",
    "            self.W1 = tf.Variable(tf.random_normal([7, 7, 3, 96], stddev=0.01))\n",
    "            self.W2 = tf.Variable(tf.random_normal([5, 5, 96, 256], stddev=0.01))\n",
    "            self.W3 = tf.Variable(tf.random_normal([3, 3, 256, 384], stddev=0.01))\n",
    "            self.W4 = tf.Variable(tf.random_normal([3, 3, 384, 384], stddev=0.01))\n",
    "            self.W5 = tf.Variable(tf.random_normal([3, 3, 384, 256], stddev=0.01))\n",
    "            self.keep_prob=tf.placeholder(tf.float32)  \n",
    "            self.Fc6_b=tf.Variable(tf.random_normal([4096]))\n",
    "            self.Fc7_b=tf.Variable(tf.random_normal([4096]))\n",
    "            self.Fc6_w= tf.get_variable(\"Fc6_w\", shape=[17920, 4096],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.Fc7_w= tf.get_variable(\"Fc7_w\", shape=[4096, 4096],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         feature 생성 하기\n",
    "        self._build_net_()\n",
    "    \n",
    "#         self.spp_fcnet(self.L5)\n",
    "    def generate_feature(self,image):\n",
    "        return self.sess.run(self.L5,feed_dict={self.X:image})\n",
    "    def _build_net_(self):\n",
    "        \n",
    "        self.L1 = tf.nn.conv2d(self.X, self.W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "            \n",
    "        self.L1 = tf.nn.relu(self.L1)\n",
    "        #LRN 넣기\n",
    "        self.L1 = tf.nn.max_pool(self.L1, ksize=[1, 3, 3, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            \n",
    "            \n",
    "        self.L2 = tf.nn.conv2d(self.L1, self.W2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "            \n",
    "        self.L2 = tf.nn.relu(self.L2)\n",
    "        #LRN 넣기\n",
    "        self.L2 = tf.nn.max_pool(self.L2, ksize=[1, 3, 3, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            \n",
    "            \n",
    "        self.L3 = tf.nn.conv2d(self.L2, self.W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        self.L3 = tf.nn.relu(self.L3)\n",
    "            \n",
    "        self.L4 = tf.nn.conv2d(self.L3, self.W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        self.L4 = tf.nn.relu(self.L4)\n",
    "            \n",
    "        self.L5 = tf.nn.conv2d(self.L4, self.W5, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        self.L5 = tf.nn.relu(self.L5)\n",
    "#         L5=self.L5\n",
    "#         a=int(L5.shape)\n",
    "#         print(\"L5 shape : \",L5.shape)\n",
    "    \n",
    "    def spp_fcnet(self,feature):# feature size : \n",
    "        a=int(feature.shape[1])\n",
    "        #SPP 6*6\n",
    "        spp6_ksize=round(a/6+0.49)\n",
    "        spp6_stride=int(a/6)\n",
    "        print(\"SPP 6 kernel\",spp6_ksize, \", stride : \",spp6_stride)\n",
    "        self.Spp6 = tf.nn.max_pool(self.L5,ksize=[1,spp6_ksize,spp6_ksize,1],strides=[1,spp6_stride,spp6_stride,1],padding=\"SAME\")\n",
    "        self.Spp6_flatten = tf.reshape(self.Spp6,[-1,256*7*7])\n",
    "            \n",
    "        #SPP 3*3\n",
    "        spp3_ksize=round(a/3+0.49)\n",
    "        spp3_stride=int(a/3)\n",
    "        print(\"SPP 3 kernel\",spp3_ksize, \", stride : \",spp3_stride)\n",
    "        self.Spp3 = tf.nn.max_pool(self.L5,ksize=[1,spp3_ksize,spp3_ksize,1],strides=[1,spp3_stride,spp3_stride,1],padding=\"SAME\")\n",
    "        self.Spp3_flatten = tf.reshape(self.Spp3,[-1,256*4*4])\n",
    "\n",
    "        #SPP 2*2\n",
    "        spp2_ksize=round(a/2+0.49)\n",
    "        spp2_stride=int(a/2)\n",
    "        print(\"SPP 2 kernel\",spp2_ksize, \", stride : \",spp2_stride)\n",
    "        self.Spp2 = tf.nn.max_pool(self.L5,ksize=[1,spp2_ksize,spp2_ksize,1],strides=[1,spp2_stride,spp2_stride,1],padding=\"SAME\")\n",
    "        self.Spp2_flatten = tf.reshape(self.Spp6,[-1,256*2*2])\n",
    "\n",
    "        #SPP 6*6\n",
    "        spp1_ksize=round(a/1+0.49)\n",
    "        spp1_stride=int(a/1)\n",
    "        print(\"SPP 1 kernel\",spp1_ksize, \", stride : \",spp1_stride)\n",
    "        self.Spp1 = tf.nn.max_pool(self.L5,ksize=[1,spp1_ksize,spp1_ksize,1],strides=[1,spp1_stride,spp1_stride,1],padding=\"SAME\")\n",
    "        self.Spp1_flatten = tf.reshape(self.Spp1,[-1,256*1*1])\n",
    "\n",
    "        self.spp_concat=tf.concat([self.Spp1_flatten,self.Spp2_flatten,self.Spp3_flatten,self.Spp6_flatten],-1)\n",
    "\n",
    "            \n",
    "            \n",
    "        self.Fc6 = tf.nn.relu(tf.matmul(self.spp_concat, self.Fc6_w) + self.Fc6_b)\n",
    "        self.Fc6 = tf.nn.dropout(self.Fc6, keep_prob=self.keep_prob)\n",
    "\n",
    "\n",
    "        self.Fc7 = tf.nn.relu(tf.matmul(self.Fc6, self.Fc7_w) + self.Fc7_b)\n",
    "        self.Fc7 = tf.nn.dropout(self.Fc7, keep_prob=self.keep_prob)\n",
    "            \n",
    "            \n",
    "#     def train(self, ):\n",
    "#         return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "#             self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "sess=tf.Session()\n",
    "m1=model(sess,\"m1\",224)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image=cv2.imread(\"D:/PASCAL/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\",cv2.IMREAD_COLOR)\n",
    "\n",
    "image=cv2.resize(image,(224,224))\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "# feature=m1.generate_feature(image)\n",
    "\n",
    "# print(\"spp6 : \",m1.Spp3)\n",
    "# print(\"spp3 : \",m1.Spp3)\n",
    "# print(\"spp2 : \",m1.Spp2)\n",
    "# print(\"spp1 : \",m1.Spp1)\n",
    "\n",
    "# print(\"spp6 flatten: \",m1.Spp6_flatten)\n",
    "# print(\"spp3 flatten: \",m1.Spp3_flatten)\n",
    "# print(\"spp2 flatten: \",m1.Spp2_flatten)\n",
    "# print(\"spp1 flatten: \",m1.Spp1_flatten)\n",
    "\n",
    "# print(m1.spp_concat)\n",
    "\n",
    "# print(m1.Fc6)\n",
    "# print(m1.Fc7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "im=[]\n",
    "im.append(image)\n",
    "im.append(image)\n",
    "im.append(image)\n",
    "print(len(im))\n",
    "m1.generate_feature(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
